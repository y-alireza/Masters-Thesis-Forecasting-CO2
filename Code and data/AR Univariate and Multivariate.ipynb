{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from math import sqrt\n",
    "from numpy import split\n",
    "from numpy import array\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.tsa.arima_model import ARIMA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate AR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# split dataset into train/test sets\n",
    "def split_dataset(data, size, train_size):\n",
    "    train_end = int(size * train_size)\n",
    "    train, test = data[0:train_end], data[train_end:size]\n",
    "    train = array(split(train, len(train)/4))\n",
    "    test = array(split(test, len(test)/4))\n",
    "    return train, test\n",
    "\n",
    "def evaluate_forecasts(actual, predicted):\n",
    "    scores = list()\n",
    "    # calculate an RMSE for each timestep\n",
    "    for i in range(actual.shape[1]):\n",
    "        mse = mean_squared_error(actual[:, i], predicted[:, i])\n",
    "        rmse = sqrt(mse)\n",
    "        scores.append(rmse)\n",
    "    # calculate overall RMSE\n",
    "    s = 0\n",
    "    for row in range(actual.shape[0]):\n",
    "        for col in range(actual.shape[1]):\n",
    "            s += (actual[row, col] - predicted[row, col])**2\n",
    "    score = sqrt(s / (actual.shape[0] * actual.shape[1]))\n",
    "    return score, scores\n",
    "\n",
    "def summarize_scores(name, score, scores):\n",
    "    s_scores = ', '.join(['%.1f' % s for s in scores])\n",
    "    print('%s: [%.3f] %s' % (name, score, s_scores))\n",
    "\n",
    "def evaluate_model(model_func, train, test):\n",
    "    history = [x for x in train]\n",
    "    # walk-forward validation over with the required timesteps\n",
    "    predictions = list()\n",
    "    for i in range(len(test)):\n",
    "        # predict\n",
    "        yhat_sequence = model_func(history)\n",
    "        # store the predictions\n",
    "        predictions.append(yhat_sequence)\n",
    "        # get real observation and add to history for predicting the next timesteps\n",
    "        history.append(test[i, :])\n",
    "    predictions = array(predictions)\n",
    "    # evaluate predictions\n",
    "    score, scores = evaluate_forecasts(test[:, :, 0], predictions)\n",
    "    return score, scores, predictions, test[:, :, 0]\n",
    "\n",
    "# convert multivariate data into a series of CO2\n",
    "def to_series(data):\n",
    "    series = [dp[:, 0] for dp in data]\n",
    "    series = array(series).flatten()\n",
    "    return series\n",
    "\n",
    "# arima forecast\n",
    "def arima_forecast(history):\n",
    "    # convert history into a univariate series\n",
    "    series = to_series(history)\n",
    "    # define and fit model\n",
    "    model = ARIMA(series, order=(4,0,0))\n",
    "    model_fit = model.fit(disp=False)\n",
    "    # make forecast\n",
    "    yhat = model_fit.predict(len(series), len(series)+3)\n",
    "    return yhat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate_ARIMA(room_data, size, train_size):\n",
    "    dataset = room_data\n",
    "    train, test = split_dataset(dataset.values, size, train_size)\n",
    "\n",
    "    for name, func in models.items():\n",
    "        score,scores, predictions, test_set = evaluate_model(func, train, test)\n",
    "        summarize_scores('ARIMA', score,scores)\n",
    "    return predictions, test_set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Room 003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARIMA: [11.616] 6.5, 9.1, 12.7, 15.9\n"
     ]
    }
   ],
   "source": [
    "models = dict()\n",
    "models['arima'] = arima_forecast\n",
    "df = pd.read_csv('data/Run example/MDB 003.csv')\n",
    "predictions, test_set = univariate_ARIMA(df, 5000,.8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from numpy import split\n",
    "from numpy import array\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import numpy as np\n",
    "\n",
    "def split_dataset(data, size, train_size):\n",
    "    train_end = int(size * train_size)\n",
    "    train, test = data[0:train_end], data[train_end:size]\n",
    "    train = array(split(train, len(train)/4))\n",
    "    test = array(split(test, len(test)/4))\n",
    "    return train, test\n",
    "\n",
    "def evaluate_forecasts(actual, predicted):\n",
    "    scores = list()\n",
    "    # calculate an RMSE score \n",
    "    for i in range(actual.shape[1]):\n",
    "        # calculate rmse\n",
    "        mse = mean_squared_error(actual[:, i], predicted[:, i])\n",
    "        rmse = sqrt(mse)\n",
    "        scores.append(rmse)\n",
    "    # calculate overall RMSE\n",
    "    s = 0\n",
    "    for row in range(actual.shape[0]):\n",
    "        for col in range(actual.shape[1]):\n",
    "            s += (actual[row, col] - predicted[row, col])**2\n",
    "    score = sqrt(s / (actual.shape[0] * actual.shape[1]))\n",
    "    return score, scores\n",
    "\n",
    "# summarize scores\n",
    "def summarize_scores(name, score, scores):\n",
    "\ts_scores = ', '.join(['%.1f' % s for s in scores])\n",
    "\tprint('%s: [%.3f] %s' % (name, score, s_scores))\n",
    "\n",
    "# evaluate a single model\n",
    "def evaluate_model(model_func, train, test, full_exog):\n",
    "    history = [x for x in train]\n",
    "    # walk-forward validation \n",
    "    predictions = list()\n",
    "    for i in range(len(test)):\n",
    "        # predict\n",
    "        yhat_sequence = model_func(history, full_exog)\n",
    "        # store the predictions\n",
    "        predictions.append(yhat_sequence)\n",
    "        # get real observation and add to history\n",
    "        history.append(test[i, :])\n",
    "    predictions = array(predictions)\n",
    "    # evaluate predictions \n",
    "    score, scores = evaluate_forecasts(test[:, :, 0], predictions)\n",
    "    return score, scores, predictions, test[:, :, 0]\n",
    "\n",
    "# convert windows of multivariate data into a series\n",
    "def to_series(data):\n",
    "    series = [dp[:, 0] for dp in data]\n",
    "    series = array(series).flatten()\n",
    "    \n",
    "    \n",
    "    df_exog = pd.DataFrame()\n",
    "    for i in range(len(data[0][0])):\n",
    "        if (i == 0):continue\n",
    "        exog = [dp[:, i] for dp in data]\n",
    "        exog = array(exog).flatten()\n",
    "        df_exog['exog{}'.format(i)] = exog\n",
    "    return series, df_exog\n",
    "\n",
    "# arima forecast\n",
    "def arima_forecast(history, full_exog):\n",
    "    # convert history into a univariate series and multivariate variables\n",
    "    series, df_exog = to_series(history)\n",
    "    exog = df_exog.to_numpy()\n",
    "    # define the model\n",
    "    model = ARIMA(series, order=(4,0,0), exog=exog)\n",
    "    # fit the model\n",
    "    model_fit = model.fit(disp=False)\n",
    "    # make forecast\n",
    "    yhat = model_fit.predict(len(series), len(series)+3, exog=full_exog[len(series):len(series)+4])\n",
    "    return yhat\n",
    "\n",
    "models = dict()\n",
    "models['arima'] = arima_forecast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_ARIMA(room_data, size, train_size):\n",
    "    models['arima'] = arima_forecast\n",
    "    dataset = room_data\n",
    "    train, test = split_dataset(dataset.values, size, train_size)\n",
    "    \n",
    "    joined_sets = np.concatenate([train,test])\n",
    "    \n",
    "    full_exog = pd.DataFrame()\n",
    "    for i in range(len(joined_sets[0][0])):\n",
    "        if (i == 0):continue\n",
    "        exog = [dp[:, i] for dp in joined_sets]\n",
    "        exog = array(exog).flatten()\n",
    "        full_exog['exog{}'.format(i)] = exog\n",
    "    \n",
    "    full_exog = full_exog.to_numpy()\n",
    "    for name, func in models.items():\n",
    "\n",
    "        score,scores, predictions, test_set = evaluate_model(func, train, test, full_exog)\n",
    "        summarize_scores('ARIMA', score,scores)\n",
    "    return predictions, test_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARIMA: [11.570] 6.5, 9.2, 12.7, 15.8\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/Run example/MDB 003.csv')\n",
    "predictions, test_set = multivariate_ARIMA(df, 5000,.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
